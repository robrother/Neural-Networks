{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradiente descendiente\n",
    "\n",
    "En este notebook implementaremos el gradiente descendiente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos los paquete necesarios\n",
    "import numpy as np\n",
    "\n",
    "# cargamos datos de ejemplo\n",
    "from data_prep import features, targets, features_test, targets_test\n",
    "\n",
    "n_records, n_features = features.shape\n",
    "last_loss = None\n",
    "\n",
    "# En este ejercicio por propósitos de analizar las salidas utilizaremos la misma semilla para los números aleatorios.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos algunas funciones necesarias\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Sigmoide\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización de los pesos\n",
    "\n",
    "En un principio no queremos tener todos los pesos en cero porque esto generaría en la salida una predicción nula. Por lo tanto, asignaremos los pesos iniciales de forma aleatoria y cercanos a cero. Otra recomendación es escalar los valores aleatorios es dependencia del número de entradas del nodo (n).\n",
    "\n",
    "$$w = rand(1,\\frac{1}{\\sqrt{n}})$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize weights. \n",
    "weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probemos la precisión de la red antes del gradiente descendiente\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparámetros de la red\n",
    "\n",
    "Los hiperpámetros de la red indican el números de veces que se realiza el gradiente descendiete (épocas-epochs), la taza de aprendizaje (learn rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "learnrate = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiente descendiente\n",
    "\n",
    "En el siguiente código encontrarás la plantilla del gradiente descendiente. Completa el código faltante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    del_w = np.zeros(weights.shape)\n",
    "    # Para todos los renglones de ejemplo, asignar a x la entrada, y a y la salida deseada\n",
    "    for x, y in zip(features.values, targets):\n",
    "\n",
    "        # TODO: calcula la predicción de la red\n",
    "        # Tip: NumPy provides a function that calculates the dot product of two arrays, \n",
    "        # which conveniently calculates h for us. \n",
    "        # The dot product multiplies two arrays element-wise, \n",
    "        # the first element in array 1 is multiplied by the first element in array 2, and so on. \n",
    "        # Then, each product is summed.\n",
    "        output = None\n",
    "\n",
    "        # TODO: calcula el error\n",
    "        error = None\n",
    "\n",
    "        # TODO: calcula el incremento\n",
    "        delta_w += 0\n",
    "\n",
    "    # TODO: Actualiza los pesos\n",
    "    weights += 0\n",
    "\n",
    "    # Ahora calculemos el error en el conjunto de datos de entrenamiento\n",
    "    if e % (epochs / 10) == 0:\n",
    "        out = sigmoid(np.dot(features, weights))\n",
    "        loss = np.mean((out - targets) ** 2)\n",
    "        if last_loss and last_loss < loss:\n",
    "            print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "        else:\n",
    "            print(\"Train loss: \", loss)\n",
    "        last_loss = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Evaluemos la precisión de la red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy on test data\n",
    "tes_out = sigmoid(np.dot(features_test, weights))\n",
    "predictions = tes_out > 0.5\n",
    "accuracy = np.mean(predictions == targets_test)\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
